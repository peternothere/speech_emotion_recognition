# Speech Emotion Recognition

This project focuses on performing Speech Emotion Recognition using audio recordings and machine learning techniques. The goal is to accurately classify emotions such as anger, calm, happy, sad, fear, disgust, and surprise from speech audio data. 
The project utilizes the Librosa library for audio analysis and a Multi-Layer Perceptron (MLP) classifier for emotion classification.



## Definition

Speech Emotion Recognition (SER) is the task of identifying emotions from speech recordings. In this project, we use audio features such as Mel-frequency cepstral coefficients (MFCC), chroma, and mel-frequency spectrogram to extract relevant information from speech signals. 
The extracted features are then used to train an MLP classifier to recognize emotions.

## Dataset

The RAVDESS dataset is used in this project. It contains audio recordings of actors portraying different emotions. Each emotion is labeled and categorized. The dataset can be accessed [here](https://zenodo.org/record/1188976).

